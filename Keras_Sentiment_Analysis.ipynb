{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3rHTFW8lDmK"
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRpkui2lNOs",
        "outputId": "28cb971a-6502-43de-a21d-409d7156a344"
      },
      "source": [
        "max_words = 20000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6icta3_1ldzB",
        "outputId": "8541f68d-8fe9-49d5-f23d-298a101e48c4"
      },
      "source": [
        "print(\"x_train length: \", len(x_train))\n",
        "print(\"x_test length: \", len(x_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train length:  25000\n",
            "x_test length:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urAm7SKGltpO",
        "outputId": "95c9a46f-1c8c-4036-fb96-a04bb086204d"
      },
      "source": [
        "word_to_index = imdb.get_word_index()\n",
        "index_to_word = {v: k for k, v in word_to_index.items()}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbsScc5Xl65Z",
        "outputId": "2a247f06-77d7-420a-902d-312491a72490"
      },
      "source": [
        "print(x_train[0])\n",
        "print(\" \".join([index_to_word[x] for x in x_train[0]]))\n",
        "\n",
        "print(\"Min value:\", min(y_train), \"Max value:\", max(y_train))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
            "Min value: 0 Max value: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3osOw_AwmWtu"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Reuun-KJmefw",
        "outputId": "9d9775bb-c068-42eb-c8c4-a6f68a336912"
      },
      "source": [
        "average_length = np.mean([len(x) for x in x_train])\n",
        "median_length = sorted([len(x) for x in x_train])[len(x_train)//2]\n",
        "\n",
        "print(\"Average Sequence length: \", average_length)\n",
        "print(\"Median Sequence length: \", median_length)\n",
        "\n",
        "max_sequence_length = 180"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Sequence length:  238.71364\n",
            "Median Sequence length:  178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6X8UYWUnLWy"
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWptFxfznX_f"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_sequence_length, padding='post', truncating='post')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA1fuNNEnr1M",
        "outputId": "b76cd933-5938-4ebc-9e9f-6a28c7e4a235"
      },
      "source": [
        "print(\"x_train shape: \", x_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (25000, 180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJHQt10YnxUx"
      },
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import LSTM, Embedding, Dense"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvEGbcsYbaAx",
        "outputId": "d9e09492-b74b-4074-fa7e-559d4db10ad4"
      },
      "source": [
        "# Single layer LSTM\n",
        "\n",
        "hidden_size = 32\n",
        "\n",
        "sl_model = Sequential()\n",
        "sl_model.add(Embedding(max_words, hidden_size))\n",
        "sl_model.add(LSTM(hidden_size, activation='tanh', dropout=0.2, recurrent_dropout=0.2))\n",
        "sl_model.add(Dense(1, activation='sigmoid'))\n",
        "sl_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PYm0H-JcLIp",
        "outputId": "c0155e6e-a7b6-440b-b0d5-13b845e62491"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "sl_model.fit(x_train, y_train, epochs=epochs, shuffle=True)\n",
        "loss, acc = sl_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 549s 670ms/step - loss: 0.6922 - accuracy: 0.5241\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 521s 666ms/step - loss: 0.6027 - accuracy: 0.6614\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 515s 659ms/step - loss: 0.6561 - accuracy: 0.6056\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 521s 667ms/step - loss: 0.4540 - accuracy: 0.8054\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 514s 658ms/step - loss: 0.4717 - accuracy: 0.8062\n",
            "782/782 [==============================] - 38s 47ms/step - loss: 0.4981 - accuracy: 0.7958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZSZZHSZcxki"
      },
      "source": [
        "# Two layer LSTM\n",
        "\n",
        "d_model = Sequential()\n",
        "d_model.add(Embedding(max_words, hidden_size))\n",
        "d_model.add(LSTM(hidden_size, activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "d_model.add(LSTM(hidden_size, activation='tanh', dropout=0.2, recurrent_dropout=0.2))\n",
        "d_model.add(Dense(1, activation='sigmoid'))\n",
        "d_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}